{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Représentation symbolique du langage naturel et inférence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import what will be needed\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse syntaxique\n",
    "\n",
    "L'analyse syntaxique du langage naturel est complexe, car le langage naturel ne possède pas la rigueur des langages formels.\n",
    "La polysémie est une des caractéristiques qui rend le langage naturel difficile à analyser, mais qui en fait aussi la richesse. La polysémie se produit :\n",
    "- au niveau des mots : `glace` est un nom et un verbe, `par` est un nom (golf) et un adverbe,\n",
    "- au niveau des phrases : `la petite brise la glace` peut se comprendre de plusieurs manières\n",
    "- au niveau de textes entiers : l'histoire regorge de paraboles comme les fables de La Fontaine destinées à critiquer tel pouvoir sans le nommer explicitement. Elle repose sur des grammaires formelles du type hors-contexte auxquelles on peut adjoindre différents mécanismes.\n",
    "\n",
    "Néammoins, l'analyse syntaxique du langage naturel repose sur l'utilisation de grammaires hors-contexte que l'on augmentera par divers mécanismes dont certains sont illustrés ci-dessous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, examinons comment NLTK permet d'analyser un énoncé selon une grammaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP\n",
    "V -> 'catches' | 'sees'\n",
    "NP -> 'Alice' | 'Bob' | Det N\n",
    "Det -> 'a' | 'an' | 'the'\n",
    "N -> 'cat' | 'dog' | 'mouse' | 'saucepan'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Alice) (VP (V catches) (NP (Det the) (N mouse))))\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.RecursiveDescentParser(grammar)\n",
    "sentence = \"Alice catches the mouse\".split()\n",
    "for tree in parser.parse(sentence):\n",
    "    print(tree)\n",
    "    # tree.draw() # Attention, ouvre une fenêtre externe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Arbre d'analyse de la phrase *Alice catches the mouse*](images/img_2022-09-05-21-36-53.png)\n",
    "\n",
    "L'analyse repose sur un algorithme récursif descendant dans ce cas.\n",
    "La bibliothèque NLTK fournit une large variété d'algorithmes d'analyse syntaxique avec diverses caractéristiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons le cas un peu particulier de la phrase :\n",
    "\n",
    "*la petite brise la glace*\n",
    "\n",
    "Nous écrivons un fragment de grammaire pour le français :\n",
    "- GN désigne un groupe nominal\n",
    "- GV désigne un groupe verbal\n",
    "- Un groupe nominal est composé d'un article, éventuellement d'un adjectif, puis d'un nom\n",
    "- Un groupe verbal est composé d'un verbe suivi d'un complément, ou bien d'un complément sous forme de pronom suivi d'un verbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> GN GV\n",
    "GV -> V GN | Pronom V\n",
    "GN -> Art N | Art Adj N\n",
    "Art -> 'le' | 'la'\n",
    "V -> 'brise' | 'glace'\n",
    "N -> 'brise' | 'glace' | 'petit' | 'petite'\n",
    "Adj -> 'petit' | 'petite'\n",
    "Pronom -> 'la' | 'lui'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "puis nous analysons la phrase :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (GN (Art la) (N petite)) (GV (V brise) (GN (Art la) (N glace))))\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.RecursiveDescentParser(grammar)\n",
    "sentence = \"la petite brise la glace\".split()\n",
    "for tree in parser.parse(sentence):\n",
    "    print(tree)\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on obtient 2 arbres d'analyses car il y a ambiguité :\n",
    "\n",
    "![](images/img_2022-09-05-21-45-34.png)\n",
    "\n",
    "![](images/img_2022-09-05-21-47-30.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez écrire vos propres grammaires dans un fichier séparé, puis les charger avec la commande :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (Det the) (Nom (Adj angry) (Nom (N bear))))\n",
      "  (VP\n",
      "    (V chased)\n",
      "    (NP\n",
      "      (Det the)\n",
      "      (Nom (Adj frightened) (Nom (Adj little) (Nom (N squirrel)))))))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4708\\118302031.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Maamar\\anaconda3\\lib\\site-packages\\nltk\\tree\\tree.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdraw_trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mdraw_trees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpretty_print\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighlight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Maamar\\anaconda3\\lib\\site-packages\\nltk\\draw\\tree.py\u001b[0m in \u001b[0;36mdraw_trees\u001b[1;34m(*trees)\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m     \"\"\"\n\u001b[1;32m-> 1008\u001b[1;33m     \u001b[0mTreeView\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Maamar\\anaconda3\\lib\\site-packages\\nltk\\draw\\tree.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0min_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Maamar\\anaconda3\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[1;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "grammar1 = nltk.data.load('file:grammar/mygrammar.cfg')\n",
    "parser = nltk.RecursiveDescentParser(grammar1)\n",
    "sentence = \"the angry bear chased the frightened little squirrel\".split()\n",
    "for tree in parser.parse(sentence):\n",
    "    print(tree)\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/img_2022-09-05-22-01-26.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accords et traits\n",
    "\n",
    "On remarquera que pour l'instant, nos exemples sont capables d'analyser des énoncés qui ne sont pas syntaxiquement corrects pour le français."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (GN (Art le) (N petit)) (GV (V brise) (GN (Art le) (N glace))))\n",
      "(S (GN (Art le) (Adj petit) (N brise)) (GV (Pronom le) (V glace)))\n"
     ]
    }
   ],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> GN GV\n",
    "GV -> V GN | Pronom V\n",
    "GN -> Art N | Art Adj N\n",
    "Art -> 'le' | 'la'\n",
    "V -> 'brise' | 'glace'\n",
    "N -> 'brise' | 'glace' | 'petit' | 'petite'\n",
    "Adj -> 'petit' | 'petite'\n",
    "Pronom -> 'le' | 'la' | 'lui'\n",
    "\"\"\")\n",
    "parser = nltk.RecursiveDescentParser(grammar)\n",
    "sentence = \"le petit brise le glace\".split()\n",
    "for tree in parser.parse(sentence):\n",
    "    print(tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aucun accord de genre n'est respecté et il en serait de même du nombre.\n",
    "L'introduction de ce type de contrainte dans une grammaire CFG ne peut se faire qu'au prix de la duplication des non-terminaux : il faudrait introduire un adjectif masculin, un adjectif féminin, un nom masculin, un nom féminin, etc. et encore multiplier par deux pour les versions singulier et pluriel ... la grammaire explose et devient impossible à maintenir.\n",
    "Pourtant, malgré leur multiplication, les règles ont la même structure. \n",
    "\n",
    "On a donc introduit un mécanisme permettant d'éviter la multiplication des non-terminaux et de propager des contraintes au travers de l'arbre d'analyse.\n",
    "Les non-terminaux seront décorés par un ensemble de traits dont les valeurs sont des termes formels.\n",
    "Les valeurs des traits dans une règle de production devront être en accord.\n",
    "Les traits peuvent avoir une variable pour valeur, dans ce cas, la valeur remontée pour ce trait est obtenue par unification entre les valeurs de ce trait dans la règle.\n",
    "Le principe est illustré ci-dessous avec deux traits GENRE et NOMBRE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le petit brise la glace -> (S[]\n",
      "  (GN[GENRE='m', NOMBRE='sg']\n",
      "    (Art[GENRE='m', NOMBRE='sg'] le)\n",
      "    (N[GENRE='m', NOMBRE='sg'] petit))\n",
      "  (GV[NOMBRE='sg']\n",
      "    (V[NOMBRE='sg'] brise)\n",
      "    (GN[GENRE='f', NOMBRE='sg']\n",
      "      (Art[GENRE='f', NOMBRE='sg'] la)\n",
      "      (N[GENRE='f', NOMBRE='sg'] glace))))\n",
      "les petits brisent la glace -> (S[]\n",
      "  (GN[GENRE='m', NOMBRE='pl']\n",
      "    (Art[NOMBRE='pl'] les)\n",
      "    (N[GENRE='m', NOMBRE='pl'] petits))\n",
      "  (GV[NOMBRE='pl']\n",
      "    (V[NOMBRE='pl'] brisent)\n",
      "    (GN[GENRE='f', NOMBRE='sg']\n",
      "      (Art[GENRE='f', NOMBRE='sg'] la)\n",
      "      (N[GENRE='f', NOMBRE='sg'] glace))))\n",
      "la petite brise le glace -> (S[]\n",
      "  (GN[GENRE='f', NOMBRE='sg']\n",
      "    (Art[GENRE='f', NOMBRE='sg'] la)\n",
      "    (Adj[GENRE='f', NOMBRE='sg'] petite)\n",
      "    (N[GENRE='f', NOMBRE='sg'] brise))\n",
      "  (GV[NOMBRE='sg']\n",
      "    (Pronom[GENRE='m', NOMBRE='sg'] le)\n",
      "    (V[NOMBRE='sg'] glace)))\n"
     ]
    }
   ],
   "source": [
    "grammar = nltk.grammar.FeatureGrammar.fromstring(\"\"\"\n",
    "S -> GN[NOMBRE=?n] GV[NOMBRE=?n]\n",
    "GV[NOMBRE=?n] -> V[NOMBRE=?n] GN | Pronom V[NOMBRE=?n] | V[NOMBRE=?n]\n",
    "GN[NOMBRE=?n,GENRE=?g] -> Art[NOMBRE=?n,GENRE=?g] N[NOMBRE=?n,GENRE=?g] | Art[NOMBRE=?n,GENRE=?g] Adj[NOMBRE=?n,GENRE=?g] N[NOMBRE=?n,GENRE=?g]\n",
    "Art[NOMBRE=sg,GENRE=m] -> 'le'\n",
    "Art[NOMBRE=sg,GENRE=f] -> 'la'\n",
    "Art[NOMBRE=pl] -> 'les'\n",
    "V[NOMBRE=sg] -> 'brise' | 'glace'\n",
    "V[NOMBRE=pl] -> 'brisent' | 'glacent'\n",
    "N[NOMBRE=sg,GENRE=f] -> 'brise' | 'glace' | 'petite'\n",
    "N[NOMBRE=pl,GENRE=f] -> 'brises' | 'glaces' | 'petites'\n",
    "N[NOMBRE=sg,GENRE=m] -> 'petit' \n",
    "N[NOMBRE=pl,GENRE=m] -> 'petits' \n",
    "Adj[NOMBRE=sg,GENRE=m] -> 'petit'\n",
    "Adj[NOMBRE=sg,GENRE=f] -> 'petite'\n",
    "Adj[NOMBRE=pl,GENRE=m] -> 'petits'\n",
    "Adj[NOMBRE=pl,GENRE=f] -> 'petites'\n",
    "Pronom[NOMBRE=sg,GENRE=m] -> 'le'| 'lui'\n",
    "Pronom[NOMBRE=sg,GENRE=f] -> 'la'\n",
    "Pronom[NOMBRE=pl] -> 'les'\n",
    "\"\"\")\n",
    "parser = nltk.FeatureEarleyChartParser(grammar)\n",
    "sentences = [ 'le petit brise la glace', 'les petits brisent la glace', 'le petite brise le glace', 'la petite brisent le glace', 'la petite brise le glace']\n",
    "for sentence in sentences:\n",
    "    for tree in parser.parse(sentence.split()):\n",
    "        print(f'{sentence} -> {tree}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit ici que plusieurs énoncés qui ne sont pas accordés correctement ne sont pas analysés.\n",
    "Le mécanisme de traits (NOMBRE, GENRE, etc.) est extrêmement puissant.\n",
    "Vous trouverez plus d'informations et d'exemples en consultant ce [chapitre](https://www.nltk.org/book/ch08.html) sur le site de la bibliothèque NLTK.\n",
    "\n",
    "Nous allons utiliser ce mécanisme pour remonter une valeur sémantique de l'énoncé : cette valeur sera obtenue par composition de la sémantique assignée aux composants individuels de l'énoncé."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bda1c67b01271daed5e4746fc62d006614e7000c5bc3b11931ce9fe70277fcae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
