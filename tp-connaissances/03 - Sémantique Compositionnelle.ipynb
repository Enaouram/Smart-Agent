{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Représentation symbolique du langage naturel et inférence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sémantique compositionnelle\n",
    "\n",
    "Dorénavant nous allons nous intéresser à la construction d'un énoncé logique correspondant à un arbre d'analyse.\n",
    "\n",
    "Chaque non-terminal de la grammaire va remonter une caractéristique (*feature*) associée supposée représenter la sémantique du groupe représenté par ce non-terminal. Il serait agréable que chaque groupe identique puisse utiliser la même sémantique, mais la langue naturelle  est complexe et il faudra parfois différenceier selon l'usage (par exemple : sujet versus complément).\n",
    "\n",
    "Nous allons construire la sémantique de l'énoncé global en combinant des éléments sémantiques atomiques.\n",
    "Pour ce faire, nous allons nous aider de $\\lambda$-expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressions logiques\n",
    "\n",
    "NLTK permet de manipuler des expressions logiques et d'effectuer toutes les opérations nécessaires à la construction d'une démonstration, en logique propositionnelle ou en logique du premier ordre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all x.(student(x) -> person(x)) student(alice) -person(alice)\n"
     ]
    }
   ],
   "source": [
    "read_expr = nltk.sem.Expression.fromstring\n",
    "e1 = read_expr('forall x.(student(x) -> person(x))')\n",
    "e2 = read_expr('student(alice)')\n",
    "e3 = read_expr('-person(alice)')\n",
    "print(e1, e2, e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous souhaitons exprimer que \"quelqu'un est un étudiant\".\n",
    "Le formalisme logique nous permet d'énoncer que :\n",
    "\n",
    "$\\forall x student(x)$\n",
    "\n",
    "ou que :\n",
    "\n",
    "$\\exists x student(x)$\n",
    "\n",
    "Ce dont nous allons avoir besoin est un peu différent. Nous avons besoin d'exprimer par une fonction la qualité d'être étudiant. \n",
    "L'application de la fonction à un argument permettra d'instancier le terme. \n",
    "Les notions de fonction et d'application sont des attributs essentiels du lambda calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\lambda$-expressions\n",
    "\n",
    "Nous allons utiliser le $\\lambda$-calcul (voir polycopié) pour dénoter des ensembles de la façon suivante :\n",
    "$$\\lambda x . [ \\text{formule logique comprenant la variable } x ]$$\n",
    "\n",
    "Considérons la phrase : \"someone gives something to Alice\", alors l'expression :\n",
    "$$\\lambda y . give(bob, alice, y)$$\n",
    "définit la fonction caractéristique des objets $y$ que Bob donne à Alice.\n",
    "\n",
    "De même :\n",
    "$$\\lambda x y. give(x, alice, y)$$\n",
    "définit la fonction caractéristique des couples $(x, y)$ de donneurs et d'objets donnés à Alice.\n",
    "\n",
    "Si $F$ est une formule logique, alors $\\lambda x. F$ désignera l'ensemble défini au moyen de $F$ des $x$ qui rendent la formule $F$ vraie.\n",
    "\n",
    "**Syntaxe :** Soit $F$ une formule logique et $x_1, \\ldots, x_n$ $n$ variables, alors l'expression $\\lambda x_1 \\ldots x_n . F$ est une $\\lambda$-expression dont $F$ est le corps.\n",
    "\n",
    "**Sémantique :** Les valeurs de la $\\lambda$-expression $\\lambda x_1 \\ldots x_n . F$ sont les valeurs du prédicat n-aire obtenu en attribuant des instances aux paramètres formels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application - Substitution - Réduction\n",
    "\n",
    "En $\\lambda$-calcul, tout est fonction.\n",
    "\n",
    "**Syntaxe :$$ \n",
    "- les variables : $x$, $y$... sont des $\\lambda$-termes ;\n",
    "- les applications : $u v$ est un $\\lambda$-terme si $u$ et $v$ sont des $\\lambda$-termes ;\n",
    "- les abstractions : $\\lambda x.v$ est un $\\lambda$-terme si $x$ est une variable et $v$ un $\\lambda$-terme.\n",
    "\n",
    "Exemple d'application : $(\\lambda x. student(x))(alice)$\n",
    "\n",
    "Autre exemple d'application : $(\\lambda x y. x + y)(\\lambda z . z * 2)$\n",
    "\n",
    "#### Substitution\n",
    "\n",
    "On définit la substition dans les $\\lambda$-termes de façon similaire à la substitution dans les termes logiques, en prenant garde aux captures possibles de variables. Exemples :\n",
    "\n",
    "- $(\\lambda x. x y)[y / a] = (\\lambda x. x a)$\n",
    "- $(\\lambda x. x y)[y / x] = (\\lambda z. z x)$ (et non $(\\lambda x. x x)$, qui est totalement différent, à cause de la capture)\n",
    "\n",
    "L'$\\alpha$-conversion identifie $\\lambda y. v$ et $\\lambda z. v[y / z]$. C'est une relation d'équivalence entre $\\lambda$-termes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réduction\n",
    "\n",
    "On définit la bêta-contraction (ou $\\beta$-contraction) de $(\\lambda x. u) v$ comme $u[x / v]$.\n",
    "\n",
    "Exemple : $(\\lambda x. x y) a$ donne $(x y)[x / a] = ay$.\n",
    "\n",
    "La réduction consiste à appliquer la $\\beta$-contraction autant de fois que possible pour mettre le terme en forme normale réduite (si possible).\n",
    "\n",
    "**Il n'est pas question ici d'expliquer le $\\lambda$-calcul dans toute sa généralité mais seulement d'en utiliser une version non-typée à des fins très pratiques de combinaison de formules logiques.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK et $\\lambda$-expressions\n",
    "\n",
    "NLTK permet de manipuler des $\\lambda$-expressions (voir polycopié).\n",
    "Ces expressions représentent des fonctions et le $\\lambda$-calcul consiste à combiner des $\\lambda$-expressions puis à les réduire.\n",
    "\n",
    "Ici, la syntaxe des $\\lambda$-expressions se combine avec celle des expressions logiques pour les rendre paramétriques et permettre de les combiner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ApplicationExpression student(alice)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = read_expr(r'(\\x.student(x))(alice)')\n",
    "l1.simplify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En revanche, avec cette syntaxe, on ne peut pas espérer obtenir un résultat pour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError 'x' is an illegal predicate name.  Individual variables may not be used as predicates.\n",
      "(\\x.x(alice))(student)\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    l2 = read_expr(r'(\\x.x(alice))(student)')\n",
    "    print(l2.simplify())\n",
    "except nltk.LogicalExpressionException as e:\n",
    "    print(f'ValueError {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le $\\lambda$-calcul permet ce type de substitution, et pour y accéder avec NLTK, il faut utiliser des variables en lettres capitales qui peuvent se substituer à des prédicats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student(alice)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    l2 = read_expr(r'(\\X.X(alice))(student)')\n",
    "    print(l2.simplify())\n",
    "except nltk.LogicalExpressionException as e:\n",
    "    print(f'ValueError {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons donc pouvoir combiner plusieurs expressions logiques fonctionnelles pour construire des formules élaborées représentant la sémantique d'un énoncé donné.\n",
    "\n",
    "Soient les expressions suivantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategory = read_expr(r'\\P Q.(all x. P(x) -> Q(x))')\n",
    "student = read_expr(r'\\x.student(x)')\n",
    "person = read_expr(r'\\x.person(x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut appliquer la règle subcategory aux catégories student et person :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(all x.student(x) -> person(x))\n"
     ]
    }
   ],
   "source": [
    "print(subcategory(student)(person).simplify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sémantique de la langue naturelle\n",
    "\n",
    "Nous allons associer à chaque symbole terminal ou non une $\\lambda$-expression que l'on appellera sa sémantique. Ces expressions seront composées par les règles pour remonter une expression au noeud de départ. Cette expression sera la traduction en langage logique de notre énoncé en langage naturel. Nous allons utiliser les *features* pour remonter la sémantique de la phrase analysée.\n",
    "\n",
    "### Note linguistique\n",
    "\n",
    "Le traitement des verbes transitifs (comme donner) ou intransitifs (comme aller) est différent de celui des verbes que l'on qualifie de *verbes d'état* en français (comme être). Il ne faut donc pas être étonné d'avoir des règles spécifiques pour être quand il est utilisé pour catégoriser. On a une illustration sur les deux exemple suivants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(grammar, sents, trace=0):\n",
    "    '''\n",
    "    Parses the sentences given.\n",
    "    Create a feature chart parser,\n",
    "    split the sentences into tokens\n",
    "    and parse.\n",
    "    Returns the SEM feature at the start symbol.\n",
    "    Beware: do not forget to state the start symbol with % start.\n",
    "    '''\n",
    "    parser = nltk.FeatureChartParser(grammar, trace=trace)\n",
    "    for sent in sents:\n",
    "        tokens = sent.split()\n",
    "        trees = parser.parse(tokens)\n",
    "        for tree in trees:\n",
    "            print(f'{sent}\\t->\\t{tree.label()[\"SEM\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.grammar.FeatureGrammar.fromstring('''\n",
    "% start S\n",
    "S[SEM=<?sv(?sn)>] -> GN[NUM=?n,SEM=?sn] GV[NUM=?n,SEM=?sv]\n",
    "GV[NUM=?n,SEM=<(?sv)(?scod)(\\Y.Y)>] -> VTrans[NUM=?n,SEM=?sv] GN[SEM=?scod] \n",
    "GV[NUM=?n,SEM=<(?sv)(?scod)(?scoi)>] -> VTrans[NUM=?n,SEM=?sv] GN[SEM=?scod] Prep GN[SEM=?scoi]\n",
    "GN[NUM=sg,SEM=?sn] -> N[NUM=sg,SEM=?sn] | Det[NUM=sg] N[NUM=sg,SEM=?sn]\n",
    "GN[NUM=pl,SEM=?sn] -> N[NUM=pl,SEM=?sn]\n",
    "Det[NUM=sg] -> 'the'\n",
    "Det[NUM=sg] -> 'a'\n",
    "VTrans[NUM=sg,SEM=<\\X Y Z.Z(\\\\x.X(\\z.Y(\\y.give(x,y,z))))>] -> 'gives'\n",
    "N[NUM=sg,SEM=<\\P.P(alice)>] -> 'Alice'\n",
    "N[NUM=sg,SEM=<\\P.P(bob)>] -> 'Bob'\n",
    "N[NUM=sg,SEM=<\\P.P(book)>] -> 'book' \n",
    "N[NUM=pl,SEM=<\\P.P(book)>] -> 'books' \n",
    "N[NUM=sg,SEM=<\\P.P(candy)>] -> 'candy' \n",
    "N[NUM=pl,SEM=<\\P.P(candies)>] -> 'candies' \n",
    "Prep -> 'to'\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob gives a book to Alice\t->\tgive(bob,alice,book)\n",
      "Bob  gives candies\t->\t\\y.give(bob,y,candies)\n"
     ]
    }
   ],
   "source": [
    "sents = ['Bob gives a book to Alice', \n",
    "         'Bob  gives candies']\n",
    "translate(grammar, sents, trace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.grammar.FeatureGrammar.fromstring('''\n",
    "% start S\n",
    "S[SEM=<?sv(?sn)>] -> GN[NUM=?n,SEM=?sn] GV[NUM=?n,SEM=?sv]\n",
    "GV[NUM=?n,SEM=<(?sv)(?sn)>] -> VState[NUM=?n,SEM=?sv] GN[SEM=?sn] \n",
    "GN[NUM=sg,SEM=?sn] -> N[NUM=sg,SEM=?sn] | Det[NUM=sg] N[NUM=sg,SEM=?sn]\n",
    "GN[NUM=pl,SEM=?sn] -> N[NUM=pl,SEM=?sn]\n",
    "Det[NUM=sg] -> 'the'\n",
    "Det[NUM=sg] -> 'a'\n",
    "VState[NUM=sg,SEM=<\\X Y.X(Y)>] -> 'is'\n",
    "N[NUM=sg,SEM=<\\P.P(alice)>] -> 'Alice'\n",
    "N[NUM=sg,SEM=<\\P.P(bob)>] -> 'Bob'\n",
    "N[NUM=sg,SEM=<\\P.P(student)>] -> 'student' \n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob is a student\t->\tstudent(bob)\n"
     ]
    }
   ],
   "source": [
    "sents = ['Bob is a student']\n",
    "translate(grammar, sents, trace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail\n",
    "\n",
    "Augmenter la grammaire ci-dessus pour analyser la phrase :\n",
    "\n",
    "Alice and Bob are students -> student(alice) and student(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.grammar.FeatureGrammar.fromstring('''\n",
    "% start S\n",
    "S[SEM=<?sv(?sn)>] -> GN[NUM=?n,SEM=?sn]  GV[NUM=?n,SEM=?sv]\n",
    "GV[NUM=?n,SEM=<(?sv)(?sn)>] -> VState[NUM=?n,SEM=?sv] GN[SEM=?sn] \n",
    "GN[NUM=sg,SEM=?sn] -> N[NUM=sg,SEM=?sn] | Det[NUM=sg] N[NUM=sg,SEM=?sn] \n",
    "GN[NUM=pl,SEM=?sn] -> N[NUM=pl,SEM=?sn] \n",
    "GN[NUM=pl,SEM=<?snconj(?sn1)(?sn2)>] -> N[SEM=?sn1] Conj[SEM=?snconj] N[SEM=?sn2] \n",
    "Det[NUM=sg] -> 'the'\n",
    "Det[NUM=sg] -> 'a'\n",
    "VState[NUM=sg,SEM=<\\X Y.X(Y)>] -> 'is'\n",
    "VState[NUM=pl,SEM=<\\X Y.X(Y)>] -> 'are'\n",
    "N[NUM=sg,SEM=<\\P.P(alice)>] -> 'Alice'\n",
    "N[NUM=sg,SEM=<\\P.P(bob)>] -> 'Bob'\n",
    "N[NUM=sg,SEM=<\\P.P(student)>] -> 'student' \n",
    "N[NUM=pl,SEM=<\\P.P(student)>] -> 'students' \n",
    "Conj[SEM=<\\Q R P.(Q(P) & R(P))>] -> 'and'\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.Al.an.Bo.ar.st.|\n",
      "|[--]  .  .  .  .| [0:1] 'Alice'\n",
      "|.  [--]  .  .  .| [1:2] 'and'\n",
      "|.  .  [--]  .  .| [2:3] 'Bob'\n",
      "|.  .  .  [--]  .| [3:4] 'are'\n",
      "|.  .  .  .  [--]| [4:5] 'students'\n",
      "|[--]  .  .  .  .| [0:1] N[NUM='sg', SEM=<\\P.P(alice)>] -> 'Alice' *\n",
      "|[--]  .  .  .  .| [0:1] GN[NUM='sg', SEM=<\\P.P(alice)>] -> N[NUM='sg', SEM=<\\P.P(alice)>] *\n",
      "|[-->  .  .  .  .| [0:1] GN[NUM='pl', SEM=<?snconj(?sn1,?sn2)>] -> N[SEM=?sn1] * Conj[SEM=?snconj] N[SEM=?sn2] {?sn1: <LambdaExpression \\P.P(alice)>}\n",
      "|[-->  .  .  .  .| [0:1] S[SEM=<?sv(?sn)>] -> GN[NUM=?n, SEM=?sn] * GV[NUM=?n, SEM=?sv] {?n: 'sg', ?sn: <LambdaExpression \\P.P(alice)>}\n",
      "|.  [--]  .  .  .| [1:2] Conj[SEM=<\\Q R P.(Q(P) & R(P))>] -> 'and' *\n",
      "|[----->  .  .  .| [0:2] GN[NUM='pl', SEM=<?snconj(?sn1,?sn2)>] -> N[SEM=?sn1] Conj[SEM=?snconj] * N[SEM=?sn2] {?sn1: <LambdaExpression \\P.P(alice)>, ?snconj: <LambdaExpression \\Q R P.(Q(P) & R(P))>}\n",
      "|.  .  [--]  .  .| [2:3] N[NUM='sg', SEM=<\\P.P(bob)>] -> 'Bob' *\n",
      "|.  .  [--]  .  .| [2:3] GN[NUM='sg', SEM=<\\P.P(bob)>] -> N[NUM='sg', SEM=<\\P.P(bob)>] *\n",
      "|.  .  [-->  .  .| [2:3] GN[NUM='pl', SEM=<?snconj(?sn1,?sn2)>] -> N[SEM=?sn1] * Conj[SEM=?snconj] N[SEM=?sn2] {?sn1: <LambdaExpression \\P.P(bob)>}\n",
      "|[--------]  .  .| [0:3] GN[NUM='pl', SEM=<\\P.(P(alice) & P(bob))>] -> N[SEM=<\\P.P(alice)>] Conj[SEM=<\\Q R P.(Q(P) & R(P))>] N[SEM=<\\P.P(bob)>] *\n",
      "|[-------->  .  .| [0:3] S[SEM=<?sv(?sn)>] -> GN[NUM=?n, SEM=?sn] * GV[NUM=?n, SEM=?sv] {?n: 'pl', ?sn: <LambdaExpression \\P.(P(alice) & P(bob))>}\n",
      "|.  .  [-->  .  .| [2:3] S[SEM=<?sv(?sn)>] -> GN[NUM=?n, SEM=?sn] * GV[NUM=?n, SEM=?sv] {?n: 'sg', ?sn: <LambdaExpression \\P.P(bob)>}\n",
      "|.  .  .  [--]  .| [3:4] VState[NUM='pl', SEM=<\\X Y.X(Y)>] -> 'are' *\n",
      "|.  .  .  [-->  .| [3:4] GV[NUM=?n, SEM=<?sv(?sn)>] -> VState[NUM=?n, SEM=?sv] * GN[SEM=?sn] {?n: 'pl', ?sv: <LambdaExpression \\X Y.X(Y)>}\n",
      "|.  .  .  .  [--]| [4:5] N[NUM='pl', SEM=<\\P.P(student)>] -> 'students' *\n",
      "|.  .  .  .  [--]| [4:5] GN[NUM='pl', SEM=<\\P.P(student)>] -> N[NUM='pl', SEM=<\\P.P(student)>] *\n",
      "|.  .  .  .  [-->| [4:5] GN[NUM='pl', SEM=<?snconj(?sn1,?sn2)>] -> N[SEM=?sn1] * Conj[SEM=?snconj] N[SEM=?sn2] {?sn1: <LambdaExpression \\P.P(student)>}\n",
      "|.  .  .  .  [-->| [4:5] S[SEM=<?sv(?sn)>] -> GN[NUM=?n, SEM=?sn] * GV[NUM=?n, SEM=?sv] {?n: 'pl', ?sn: <LambdaExpression \\P.P(student)>}\n",
      "|.  .  .  [-----]| [3:5] GV[NUM='pl', SEM=<\\Y.Y(student)>] -> VState[NUM='pl', SEM=<\\X Y.X(Y)>] GN[SEM=<\\P.P(student)>] *\n",
      "|[==============]| [0:5] S[SEM=<(student(alice) & student(bob))>] -> GN[NUM='pl', SEM=<\\P.(P(alice) & P(bob))>] GV[NUM='pl', SEM=<\\Y.Y(student)>] *\n",
      "Alice and Bob are students\t->\t(student(alice) & student(bob))\n"
     ]
    }
   ],
   "source": [
    "sents = ['Alice and Bob are students']\n",
    "translate(grammar, sents, trace=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajouter la négation :\n",
    "\n",
    "Alice is not a student -> -student(alice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.grammar.FeatureGrammar.fromstring('''\n",
    "% start S\n",
    "S[SEM=<?sv(?sn)>] -> GN[NUM=?n,SEM=?sn] GV[NUM=?n,SEM=?sv]\n",
    "GV[NUM=?n,SEM=<(?sv)(?neg)(?sn)>] -> VState[NUM=?n,SEM=?sv] GN[SEM=?sn] | VState[NUM=?n,SEM=?sv] ADV[SEM=?neg] GN[SEM=?sn]\n",
    "GN[NUM=sg,SEM=?sn] -> N[NUM=sg,SEM=?sn] | Det[NUM=sg] N[NUM=sg,SEM=?sn]\n",
    "GN[NUM=pl,SEM=?sn] -> N[NUM=pl,SEM=?sn]\n",
    "GN[NUM=pl,SEM=<?snconj(?sn1)(?sn2)>] -> N[SEM=?sn1] Conj[SEM=?snconj] N[SEM=?sn2] \n",
    "Det[NUM=sg] -> 'the'\n",
    "Det[NUM=sg] -> 'a'\n",
    "Conj[SEM=<\\Q R P . (Q(P) & R(P))>] -> 'and'\n",
    "ADV[SEM=<\\P x. (-P(x))>] -> 'not'                                                                                                  \n",
    "VState[NUM=sg,SEM=<\\X Y.X(Y)>] -> 'is'\n",
    "VState[NUM=pl,SEM=<\\X Y.X(Y)>] -> 'are'\n",
    "N[NUM=sg,SEM=<\\P.P(alice)>] -> 'Alice'\n",
    "N[NUM=sg,SEM=<\\P.P(bob)>] -> 'Bob'\n",
    "N[NUM=sg,SEM=<\\P.P(student)>] -> 'student'                                                  \n",
    "N[NUM=pl,SEM=<\\P.P(student)>] -> 'students'\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.Al.is.no.a .st.|\n",
      "|[--]  .  .  .  .| [0:1] 'Alice'\n",
      "|.  [--]  .  .  .| [1:2] 'is'\n",
      "|.  .  [--]  .  .| [2:3] 'not'\n",
      "|.  .  .  [--]  .| [3:4] 'a'\n",
      "|.  .  .  .  [--]| [4:5] 'student'\n",
      "|[--]  .  .  .  .| [0:1] N[NUM='sg', SEM=<\\P.P(alice)>] -> 'Alice' *\n",
      "|[--]  .  .  .  .| [0:1] GN[NUM='sg', SEM=<\\P.P(alice)>] -> N[NUM='sg', SEM=<\\P.P(alice)>] *\n",
      "|[-->  .  .  .  .| [0:1] GN[NUM='pl', SEM=<?snconj(?sn1,?sn2)>] -> N[SEM=?sn1] * Conj[SEM=?snconj] N[SEM=?sn2] {?sn1: <LambdaExpression \\P.P(alice)>}\n",
      "|[-->  .  .  .  .| [0:1] S[SEM=<?sv(?sn)>] -> GN[NUM=?n, SEM=?sn] * GV[NUM=?n, SEM=?sv] {?n: 'sg', ?sn: <LambdaExpression \\P.P(alice)>}\n",
      "|.  [--]  .  .  .| [1:2] VState[NUM='sg', SEM=<\\X Y.X(Y)>] -> 'is' *\n",
      "|.  [-->  .  .  .| [1:2] GV[NUM=?n, SEM=<?sv(?neg,?sn)>] -> VState[NUM=?n, SEM=?sv] * GN[SEM=?sn] {?n: 'sg', ?sv: <LambdaExpression \\X Y.X(Y)>}\n",
      "|.  [-->  .  .  .| [1:2] GV[NUM=?n, SEM=<?sv(?neg,?sn)>] -> VState[NUM=?n, SEM=?sv] * ADV[SEM=?neg] GN[SEM=?sn] {?n: 'sg', ?sv: <LambdaExpression \\X Y.X(Y)>}\n",
      "|.  .  [--]  .  .| [2:3] ADV[SEM=<\\P x.-P(x)>] -> 'not' *\n",
      "|.  [----->  .  .| [1:3] GV[NUM=?n, SEM=<?sv(?neg,?sn)>] -> VState[NUM=?n, SEM=?sv] ADV[SEM=?neg] * GN[SEM=?sn] {?n: 'sg', ?neg: <LambdaExpression \\P x.-P(x)>, ?sv: <LambdaExpression \\X Y.X(Y)>}\n",
      "|.  .  .  [--]  .| [3:4] Det[NUM='sg'] -> 'a' *\n",
      "|.  .  .  [-->  .| [3:4] GN[NUM='sg', SEM=?sn] -> Det[NUM='sg'] * N[NUM='sg', SEM=?sn] {}\n",
      "|.  .  .  .  [--]| [4:5] N[NUM='sg', SEM=<\\P.P(student)>] -> 'student' *\n",
      "|.  .  .  .  [--]| [4:5] GN[NUM='sg', SEM=<\\P.P(student)>] -> N[NUM='sg', SEM=<\\P.P(student)>] *\n",
      "|.  .  .  .  [-->| [4:5] GN[NUM='pl', SEM=<?snconj(?sn1,?sn2)>] -> N[SEM=?sn1] * Conj[SEM=?snconj] N[SEM=?sn2] {?sn1: <LambdaExpression \\P.P(student)>}\n",
      "|.  .  .  [-----]| [3:5] GN[NUM='sg', SEM=<\\P.P(student)>] -> Det[NUM='sg'] N[NUM='sg', SEM=<\\P.P(student)>] *\n",
      "|.  .  .  [----->| [3:5] S[SEM=<?sv(?sn)>] -> GN[NUM=?n, SEM=?sn] * GV[NUM=?n, SEM=?sv] {?n: 'sg', ?sn: <LambdaExpression \\P.P(student)>}\n",
      "|.  [-----------]| [1:5] GV[NUM='sg', SEM=<\\x.-x(student)>] -> VState[NUM='sg', SEM=<\\X Y.X(Y)>] ADV[SEM=<\\P x.-P(x)>] GN[SEM=<\\P.P(student)>] *\n",
      "|[==============]| [0:5] S[SEM=<-student(alice)>] -> GN[NUM='sg', SEM=<\\P.P(alice)>] GV[NUM='sg', SEM=<\\x.-x(student)>] *\n",
      "|.  .  .  .  [-->| [4:5] S[SEM=<?sv(?sn)>] -> GN[NUM=?n, SEM=?sn] * GV[NUM=?n, SEM=?sv] {?n: 'sg', ?sn: <LambdaExpression \\P.P(student)>}\n",
      "Alice is not a student\t->\t-student(alice)\n"
     ]
    }
   ],
   "source": [
    "sents = ['Alice is not a student']\n",
    "translate(grammar, sents, trace=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bda1c67b01271daed5e4746fc62d006614e7000c5bc3b11931ce9fe70277fcae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
